{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Record-Linkage\" data-toc-modified-id=\"Record-Linkage-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Record Linkage</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Principles-of-Record-Linkage\" data-toc-modified-id=\"The-Principles-of-Record-Linkage-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>The Principles of Record Linkage</a></span></li><li><span><a href=\"#Linking-Patents-to-Grants:-individual-and-organization-levels\" data-toc-modified-id=\"Linking-Patents-to-Grants:-individual-and-organization-levels-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Linking Patents to Grants: individual and organization levels</a></span></li><li><span><a href=\"#Python-Setup\" data-toc-modified-id=\"Python-Setup-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Python Setup</a></span></li></ul></li><li><span><a href=\"#Data-Exploration:-Know-Your-Data\" data-toc-modified-id=\"Data-Exploration:-Know-Your-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Exploration: Know Your Data</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Individual-level-links:-inventor-(patent)-<->-principal-investigator-(grant)\" data-toc-modified-id=\"Individual-level-links:-inventor-(patent)-<->-principal-investigator-(grant)-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Individual-level links: inventor (patent) &lt;-&gt; principal investigator (grant)</a></span><ul class=\"toc-item\"><li><span><a href=\"#PatentsView:-inventor-names-on-patents\" data-toc-modified-id=\"PatentsView:-inventor-names-on-patents-2.0.1.1\"><span class=\"toc-item-num\">2.0.1.1&nbsp;&nbsp;</span>PatentsView: inventor names on patents</a></span></li><li><span><a href=\"#FedRePORTER:-principal-investigator-names-on-grants\" data-toc-modified-id=\"FedRePORTER:-principal-investigator-names-on-grants-2.0.1.2\"><span class=\"toc-item-num\">2.0.1.2&nbsp;&nbsp;</span>FedRePORTER: principal investigator names on grants</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Data-Cleaning\" data-toc-modified-id=\"Data-Cleaning-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Data Cleaning</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Importance-of-Pre-Processing\" data-toc-modified-id=\"The-Importance-of-Pre-Processing-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The Importance of Pre-Processing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Individual-level-links\" data-toc-modified-id=\"Individual-level-links-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>Individual-level links</a></span><ul class=\"toc-item\"><li><span><a href=\"#Clean-Inventor-Data\" data-toc-modified-id=\"Clean-Inventor-Data-3.1.1.1\"><span class=\"toc-item-num\">3.1.1.1&nbsp;&nbsp;</span>Clean Inventor Data</a></span></li><li><span><a href=\"#Clean-Grant-Data\" data-toc-modified-id=\"Clean-Grant-Data-3.1.1.2\"><span class=\"toc-item-num\">3.1.1.2&nbsp;&nbsp;</span>Clean Grant Data</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Deterministic-Matching\" data-toc-modified-id=\"Deterministic-Matching-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Deterministic Matching</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Individual-level-links\" data-toc-modified-id=\"Individual-level-links-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Individual-level links</a></span><ul class=\"toc-item\"><li><span><a href=\"#REGEX-CHEATSHEET\" data-toc-modified-id=\"REGEX-CHEATSHEET-4.0.1.1\"><span class=\"toc-item-num\">4.0.1.1&nbsp;&nbsp;</span>REGEX CHEATSHEET</a></span></li><li><span><a href=\"#EXAMPLES\" data-toc-modified-id=\"EXAMPLES-4.0.1.2\"><span class=\"toc-item-num\">4.0.1.2&nbsp;&nbsp;</span>EXAMPLES</a></span></li></ul></li></ul></li><li><span><a href=\"#References-and-Further-Readings\" data-toc-modified-id=\"References-and-Further-Readings-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>References and Further Readings</a></span><ul class=\"toc-item\"><li><span><a href=\"#Record-Linkage\" data-toc-modified-id=\"Record-Linkage-4.1.1\"><span class=\"toc-item-num\">4.1.1&nbsp;&nbsp;</span>Record Linkage</a></span></li><li><span><a href=\"#Parsing\" data-toc-modified-id=\"Parsing-4.1.2\"><span class=\"toc-item-num\">4.1.2&nbsp;&nbsp;</span>Parsing</a></span></li><li><span><a href=\"#Regular-Expression\" data-toc-modified-id=\"Regular-Expression-4.1.3\"><span class=\"toc-item-num\">4.1.3&nbsp;&nbsp;</span>Regular Expression</a></span></li><li><span><a href=\"#Record-Linkage-Python-package\" data-toc-modified-id=\"Record-Linkage-Python-package-4.1.4\"><span class=\"toc-item-num\">4.1.4&nbsp;&nbsp;</span>Record Linkage Python package</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributors:\n",
    "Rayid Ghani, Frauke Kreuter, Julia Lane, Brian Kim, Adrianne Bradford, Alex Engler, Nicolas Guetta Jeanrenaud, Graham Henke, Daniela Hochfellner, Clayton Hunter, Avishek Kumar, Jonathan Morgan, Ekaterina Levitskaya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will provide you with an instruction into Record Linkage using Python. Upon completion of this notebook you will be able to apply record linkage techniques using the `recordlinkage` package to combine data from different sources in Python. \n",
    "It will lead you through all the steps necessary for a sucessful record linkage starting with data preparation  including pre-processing, cleaning and standardization of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Principles of Record Linkage\n",
    "The goal of record linkage is to determine if pairs of records describe the same entity. For instance, this is important for removing duplicates from a data source or joining two separate data sources together. Record linkage also goes by the terms data matching, merge/purge, duplication detection, de-duping, reference matching, entity resolution, disambiguation, co-reference/anaphora in various fields.\n",
    "\n",
    "There are several approaches to record linkage that include \n",
    "    - exact matching,\n",
    "    - rule-based linking, \n",
    "    - probabilistic linking. \n",
    "- An example of **exact matching** is joining records based on a direct identifier. This is what we have already have done in SQL by joining tables. \n",
    "- **Rule-based matching** involves applying a cascading set of rules that reflect the domain knowledge of the records being linked. \n",
    "- In **probabilistic record linkages**, linkage weights are estimated to calculate the probability of a certain match.\n",
    "\n",
    "In practical applications you will need record linkage techiques to combine information addressing the same entity that is stored in different data sources. Record linkage will also help you to address the quality of different data sources. For example, if one of your databases has missing values you might be able to fill those by finding an identical pair in a different data source. Overall, the main applications of record linkage are:\n",
    "    1. Merging two or more data files. \n",
    "    2. Identifying the intersection of the two data sets. \n",
    "    3. Updating data files (with the data row of the other data files) and imputing missing data.\n",
    "    4. Entity disambiguation and de-duplication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linking Patents to Grants: individual and organization levels\n",
    "\n",
    "In this class we will link records obtained from the **PatentsView** (https://www.patentsview.org/download/) to the data on federal grants in **FedRePORTER** (https://federalreporter.nih.gov/FileDownload). In both datasets we have names that we can use to link: inventor names on patents and principal investigator names on grants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T00:05:31.897322Z",
     "start_time": "2020-01-24T00:05:31.874358Z"
    }
   },
   "source": [
    "**About USPTO/PatentsView**\n",
    "\n",
    "The PatentsView platform links inventors, organizations, locations, and patenting activity since 1976. \n",
    "\n",
    "\n",
    "**Key variables of interest**:\n",
    "\n",
    "**Patent**\n",
    "- Patent processing time (duration between a patent application filing date and\n",
    "grant date)\n",
    "- Title\n",
    "- Type of patent document (utility, design, plant, reissue, defensive, and statutory\n",
    "invention registration—offer different kinds of protection for distinct types of\n",
    "subject matter)\n",
    "- Cited patent (patent is cited when it appears as a reference in another patent or\n",
    "patent application)\n",
    "- Citing patent (patent that cites a patent or patent application as a reference in its\n",
    "&#39;references cited&#39; section)\n",
    "- Grant date (date a patent was issued by the USPTO)\n",
    "- International Patent Classification (IPC) (system of patent classifications\n",
    "published by the World Intellectual Property Organization (WIPO))\n",
    "\n",
    "**Assignee** (the name of the entity—company, foundation, partnership, holding company\n",
    "or individual—that owns the patent)\n",
    "- First name (if assignee is individual)\n",
    "- Last name (if assignee is individual)\n",
    "- Organization name (if assignee is organization)\n",
    "- Type (classification of assignee)\n",
    "- Location (City, State, Country, Latitude, Longitude, County, FIPS code (state), FIPS code (county))\n",
    "\n",
    "**Inventor** (the individual who conceived the invention)\n",
    "- First name\n",
    "- Last name\n",
    "- Gender\n",
    "- Location (City, State, Country, Latitude, Longitude, County, FIPS code (state), FIPS code (county))\n",
    "- Co-inventor (a person who appears on the same patent or patent application as\n",
    "another inventor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**About Federal RePORTER**\n",
    "\n",
    "Federal RePORTER is a collaborative effort led by STAR METRICS® to create a searchable\n",
    "database of scientific awards from agencies (across agencies or fiscal years, by the award&#39;s\n",
    "project leader, or by a text search of a project&#39;s title, terms, or abstracts). The National Institutes of Health (NIH) and the National Science Foundation (NSF), under the auspices of Office of Science and Technology Policy (OSTP), are leading this project with funding provided by NIH, NSF, the U.S. Department of Agriculture, and the Environmental Protection Agency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T00:10:44.220943Z",
     "start_time": "2020-01-24T00:10:44.210446Z"
    }
   },
   "source": [
    "Agencies with data in Federal RePORTER: DOD (Department of Defense), ED (Department of Education), Environmental Protection Agency (EPA), HHS (Department of Health and Human Services), National Aeronautics and Space Administration (NASA), National Science Foundation (NSF), USDA (United States Department of Agriculture), U.S. Department of Veterans Affairs (VA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key variables of interest**:\n",
    "- Project description\n",
    "    - Title\n",
    "    - Abstract\n",
    "    - Terms (keywords from the project title and abstract)\n",
    "- Project duration\n",
    "    - Start date\n",
    "    - End date\n",
    "- Total cost of a project\n",
    "- Financial year\n",
    "- Federal agency, department\n",
    "- Principal Investigator (PI) Project Leader\n",
    "    - First name\n",
    "    - Last name\n",
    "- Other PIs\n",
    "    - First name\n",
    "    - Last name\n",
    "- Organization name\n",
    "- Organization location (City, State, Zip, Country)\n",
    "- CFDA code (The Catalog of Federal Domestic Assistance, federal financial assistance\n",
    "and nonfinancial assistance programs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions for group discussion:** \n",
    "- What variables would you use for record linkage using these datasets?\n",
    "- What problems do you anticipate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Subset**: The FedRePORTER dataset includes records from year 2010, and PatentsView dataset includes records from 2015-2019 of patents with government interest (in order to account for a time lag between the start of a grant and potential outputs (registered patents) from a grant)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary Python packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:00.931067Z",
     "start_time": "2020-01-24T14:08:00.927558Z"
    }
   },
   "outputs": [],
   "source": [
    "# data import and manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# record linkage and preprocessing\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.preprocessing import clean, phonetic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration: Know Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual-level links: inventor (patent) <-> principal investigator (grant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PatentsView: inventor names on patents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:01.362133Z",
     "start_time": "2020-01-24T14:08:01.341889Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import CSV into a dataframe\n",
    "inventors = pd.read_csv('../Data/patentsview_inventors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:01.786301Z",
     "start_time": "2020-01-24T14:08:01.772647Z"
    }
   },
   "outputs": [],
   "source": [
    "# View first rows of the dataframe\n",
    "inventors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:02.263910Z",
     "start_time": "2020-01-24T14:08:02.251228Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that `inventor_state` information appears to be missing in some cases (3,994 records vs total 4,841 records).\n",
    "\n",
    "We can check the rows that are missing by calling `.isnull()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:02.798567Z",
     "start_time": "2020-01-24T14:08:02.771189Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show rows which are null in `inventor_state` column\n",
    "inventors[inventors['inventor_state'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our records are not filtered by only US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:03.566284Z",
     "start_time": "2020-01-24T14:08:03.559637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check unique values in the `inventor_country` column\n",
    "inventors['inventor_country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter by only those records which are in the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:04.387732Z",
     "start_time": "2020-01-24T14:08:04.381138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter by those rows where country is US\n",
    "inventors = inventors[inventors['inventor_country'] == 'US']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:05.062497Z",
     "start_time": "2020-01-24T14:08:05.055875Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check that now we only have US as an inventor country\n",
    "inventors['inventor_country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:05.547354Z",
     "start_time": "2020-01-24T14:08:05.537630Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors['patent_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be linking on name and location. What do you observe in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:06.014919Z",
     "start_time": "2020-01-24T14:08:05.999689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the tail of the table \n",
    "inventors.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First name includes first and middle names (potentially parse out)\n",
    "- First and last names are capitalized\n",
    "- The same person (with the same inventor id) can have different associated locations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T01:29:47.602379Z",
     "start_time": "2020-01-22T01:29:47.588431Z"
    }
   },
   "source": [
    "Check most frequent counts of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:06.490324Z",
     "start_time": "2020-01-24T14:08:06.479501Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors['inventor_city'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:06.968601Z",
     "start_time": "2020-01-24T14:08:06.954889Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors['inventor_state'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T23:20:15.266678Z",
     "start_time": "2020-01-21T23:20:15.256670Z"
    }
   },
   "source": [
    "#### FedRePORTER: principal investigator names on grants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:07.904305Z",
     "start_time": "2020-01-24T14:08:07.637415Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read-in the dataset into a dataframe\n",
    "pi = pd.read_csv('../Data/fedreporter_pi_names_grants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:08.394233Z",
     "start_time": "2020-01-24T14:08:08.382270Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show first rows of the dataframe\n",
    "pi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:09.061721Z",
     "start_time": "2020-01-24T14:08:09.029334Z"
    }
   },
   "outputs": [],
   "source": [
    "pi.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check which countries are there in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:09.661481Z",
     "start_time": "2020-01-24T14:08:09.627045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call .unique() function\n",
    "pi[' ORGANIZATION_COUNTRY'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter by only US like we did with the PatentsView dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:10.269812Z",
     "start_time": "2020-01-24T14:08:10.238322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filter by only those rows with US as an organization_country\n",
    "pi = pi[pi[' ORGANIZATION_COUNTRY'] == 'UNITED STATES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:10.874738Z",
     "start_time": "2020-01-24T14:08:10.863219Z"
    }
   },
   "outputs": [],
   "source": [
    "# Call .unique() function\n",
    "pi[' ORGANIZATION_COUNTRY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:11.327863Z",
     "start_time": "2020-01-24T14:08:11.307054Z"
    }
   },
   "outputs": [],
   "source": [
    "pi[' ORGANIZATION_CITY'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:11.821421Z",
     "start_time": "2020-01-24T14:08:11.800966Z"
    }
   },
   "outputs": [],
   "source": [
    "pi[' ORGANIZATION_STATE'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare inventor and grants table: what types of cleaning/standardization would we need to do?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:12.271339Z",
     "start_time": "2020-01-24T14:08:12.257308Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:12.713453Z",
     "start_time": "2020-01-24T14:08:12.701209Z"
    }
   },
   "outputs": [],
   "source": [
    "pi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Checkpoint 1: Explore organization-level data from PatentsView and FedRePORTER**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try exploring organization-level data for both PatentsView and FedRePORTER using functions for data exploration used in the examples above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:13.196090Z",
     "start_time": "2020-01-24T14:08:13.179161Z"
    }
   },
   "outputs": [],
   "source": [
    "assignees = pd.read_csv('../Data/patentsview_assignee_org_names.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:13.817847Z",
     "start_time": "2020-01-24T14:08:13.699152Z"
    }
   },
   "outputs": [],
   "source": [
    "organizations = pd.read_csv('../Data/fedreporter_org_names_grants.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:07:23.132815Z",
     "start_time": "2020-01-24T14:07:23.125745Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Importance of Pre-Processing\n",
    "Data pre-processing is an important step in a data anlysis project in general, in record linkage applications in particular. The goal of pre-processing is to transform messy data into a dataset that can be used in a project workflow.\n",
    "\n",
    "Linking records from different data sources comes with different challenges that need to be addressed by the analyst. The analyst must determine whether or not two entities (individuals, businesses, geographical units) on two different files are the same. This determination is not always easy. In most of the cases there is no common uniquely identifing characteristic for a entity. For example, is Bob Miller from New Yor the same person as Bob Miller from Chicago in a given dataset? This detemination has to be executed carefully because consequences of wrong linkages may be substantial (is person X the same person as the person X on the list of identified terrorists). Pre-processing can help to make better informed decisions.\n",
    "\n",
    "Pre-processing can be difficult because there are a lot of things to keep in mind. For example, data input errors, such as typos, misspellings, truncation, abbreviations, and missing values need to be corrected. Literature shows that preprocessing can improve matches. \n",
    "\n",
    "“In situations of reasonably high-quality data, preprocessing can yield a greater improvement in matching efficiency than string comparators and ‘optimized’ parameters. In some situations, 90% of the improvement in matching efficiency may be due to preprocessing” (Winkler 2009).\n",
    "\n",
    "The most common reason why matching projects fail is lack of time and resources for data cleaning. \n",
    "\n",
    "In the following section we will walk you through some pre-processing steps, these include but are not limited to removing spaces, parsing fields, and standardizing strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual-level links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Inventor Data\n",
    "We will start by cleaning and preprocessing the inventor data. We need to remove whitespaces, make sure that everything is in lower case, we need to parse the first name and the last name, and harmonize all the other information we need for the linkage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `recordlinkage` package comes with a built-in cleaning function we can use. The `clean()` function removes any characters such as `-`, `.`, `/`, `:`, brackets of all types, and also lowercases by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:16.389020Z",
     "start_time": "2020-01-24T14:08:16.366263Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's take a look at names before\n",
    "inventors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:17.060889Z",
     "start_time": "2020-01-24T14:08:16.989537Z"
    }
   },
   "outputs": [],
   "source": [
    "# Cleaning names (using the record linkage package tool)\n",
    "inventors['name_last'] = clean(inventors['name_last'])\n",
    "inventors['name_first'] = clean(inventors['name_first'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:17.599770Z",
     "start_time": "2020-01-24T14:08:17.583093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's take a look at names after the cleaning\n",
    "inventors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can parse and extract middle names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:18.237018Z",
     "start_time": "2020-01-24T14:08:18.162962Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split by white space and extract first element for the first name,\n",
    "# second element for the middle name\n",
    "inventors['name_middle'] = inventors.name_first.str.split(' ').str.get(1)\n",
    "inventors['name_first'] = inventors.name_first.str.split(' ').str.get(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:18.775346Z",
     "start_time": "2020-01-24T14:08:18.761753Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are done with the inital data prep work for the inventor file. Please keep in mind that we just provided some examples for you to demonstrate the process. You can add as many further steps to it as necessary. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean Grant Data\n",
    "Now we will clean and preprocess the grants data. We need a dataset that has the first, middle and last name of the researcher, the city, state, and country information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:19.373928Z",
     "start_time": "2020-01-24T14:08:19.357084Z"
    }
   },
   "outputs": [],
   "source": [
    "pi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can start cleaning the data and extract the information that we need to compare it to the inventor file. You want to find as many variables as you can match to as possible. You can also see that we have two field with names. You have the PI field, but you can extract more names from the OTHER PIDS fields if you are interested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:20.756177Z",
     "start_time": "2020-01-24T14:08:20.020608Z"
    }
   },
   "outputs": [],
   "source": [
    "pi[' CONTACT_PI_PROJECT_LEADER'] = clean(pi[' CONTACT_PI_PROJECT_LEADER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:22.030238Z",
     "start_time": "2020-01-24T14:08:21.286588Z"
    }
   },
   "outputs": [],
   "source": [
    "pi['name_first'] = pi[' CONTACT_PI_PROJECT_LEADER'].str.split(' ').str.get(1)\n",
    "pi['name_last'] = pi[' CONTACT_PI_PROJECT_LEADER'].str.split(' ').str.get(0)\n",
    "pi['name_middle'] = pi[' CONTACT_PI_PROJECT_LEADER'].str.split(' ').str.get(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:22.693018Z",
     "start_time": "2020-01-24T14:08:22.655521Z"
    }
   },
   "outputs": [],
   "source": [
    "pi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add one more thing: **phonetic processing**.\n",
    "\n",
    "Sometimes, words or names are recorded differently because they are written down as they sound. This can result in failed matches, because the same organization or individual will technically have different written names, even though the names would sound identically when pronounced out loud. To avoid these issues, we will add onoe more thing: a soundex (a phonetic algorithm for indexing names by sound, as pronounced in English).\n",
    "\n",
    "The `phonetic()` function is used to convert strings into their corresponding phonetic codes. This is particularly useful when comparing names where different possible spellings make it difficult to find exact matches (e.g. Jillian and Gillian).\n",
    "\n",
    "Let's add a column called `phonetic_name` to our existing table, which will contain the result of applying a `phonetic` function to the name (the phonetic transcription of the name). We are using a method called NYSIIS - the New York State Identification and Intelligence System phonetic code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:28.618910Z",
     "start_time": "2020-01-24T14:08:27.673533Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors[\"phonetic_first\"] = phonetic(inventors[\"name_first\"], method=\"nysiis\")\n",
    "inventors[\"phonetic_last\"] = phonetic(inventors[\"name_last\"], method=\"nysiis\")\n",
    "inventors[\"phonetic_middle\"] = phonetic(inventors[\"name_middle\"], method=\"nysiis\")\n",
    "\n",
    "pi[\"phonetic_first\"] = phonetic(pi[\"name_first\"], method=\"nysiis\")\n",
    "pi[\"phonetic_last\"] = phonetic(pi[\"name_last\"], method=\"nysiis\")\n",
    "pi[\"phonetic_middle\"] = phonetic(pi[\"name_middle\"], method=\"nysiis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:29.231081Z",
     "start_time": "2020-01-24T14:08:29.185657Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:30.319292Z",
     "start_time": "2020-01-24T14:08:30.293494Z"
    }
   },
   "outputs": [],
   "source": [
    "pi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Checkpoint 2: Clean organization-level data**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `clean` function above, remove white space, and find phonetic transcriptions of organization names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:07:27.479100Z",
     "start_time": "2020-01-24T14:07:27.464260Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here...\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual-level links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first do an exact match (merge) on the **first, middle, last name** and examine the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:37.455461Z",
     "start_time": "2020-01-24T14:08:37.191526Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge on first, middle, last name\n",
    "merge_name = inventors.merge(pi,on=['name_first','name_last','name_middle'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's count how many unique inventor IDs and PI names got matched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:38.330109Z",
     "start_time": "2020-01-24T14:08:38.321829Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's check the count of unique inventor_ids\n",
    "merge_name['inventor_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now merge on the **phonetic first, middle, last name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:40.630385Z",
     "start_time": "2020-01-24T14:08:40.477841Z"
    }
   },
   "outputs": [],
   "source": [
    "# Merge on phonetic first, middle, last name\n",
    "merge_name_phonetic_middle = inventors.merge(pi,on=['phonetic_first','phonetic_last','phonetic_middle'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:41.146596Z",
     "start_time": "2020-01-24T14:08:41.140676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's check the count of unique inventor_ids\n",
    "merge_name_phonetic_middle['inventor_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can enlarge your links and only merge on **first and last name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:44.588372Z",
     "start_time": "2020-01-24T14:08:44.434250Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_name_first_last = inventors.merge(pi,on=['name_first','name_last'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:45.109034Z",
     "start_time": "2020-01-24T14:08:45.100831Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check the counts\n",
    "merge_name_first_last['inventor_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try merging on **phonetic first and last name**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:47.160148Z",
     "start_time": "2020-01-24T14:08:47.014443Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_name_phonetic = inventors.merge(pi,on=['phonetic_first','phonetic_last'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:47.679196Z",
     "start_time": "2020-01-24T14:08:47.671819Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_name_phonetic['inventor_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we blocked by state?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:50.702811Z",
     "start_time": "2020-01-24T14:08:50.568627Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rename columns in both datasets to the same name\n",
    "inventors = inventors.rename(columns={'inventor_state':'state'})\n",
    "pi = pi.rename(columns={' ORGANIZATION_STATE':'state'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-23T01:13:34.620172Z",
     "start_time": "2020-01-23T01:13:34.611235Z"
    }
   },
   "source": [
    "Merge on **first, middle, last name, and state**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:54.368754Z",
     "start_time": "2020-01-24T14:08:54.220228Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_name_state = inventors.merge(pi,on=['name_first','name_last','name_middle','state'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many matches did we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:08:55.457575Z",
     "start_time": "2020-01-24T14:08:55.449147Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_name_state['inventor_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:00.618563Z",
     "start_time": "2020-01-24T14:09:00.460766Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_phonetic_name_state = inventors.merge(pi,on=['phonetic_first','phonetic_last','phonetic_middle','state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:01.130691Z",
     "start_time": "2020-01-24T14:09:01.124743Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_phonetic_name_state['inventor_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try blocking by **full name, city and state**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:08.334950Z",
     "start_time": "2020-01-24T14:09:08.295112Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:13.738365Z",
     "start_time": "2020-01-24T14:09:13.712641Z"
    }
   },
   "outputs": [],
   "source": [
    "pi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:17.286825Z",
     "start_time": "2020-01-24T14:09:17.273931Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors['inventor_city'] = inventors['inventor_city'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:17.954049Z",
     "start_time": "2020-01-24T14:09:17.934740Z"
    }
   },
   "outputs": [],
   "source": [
    "inventors = inventors.rename(columns={'inventor_city':'city'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:19.102560Z",
     "start_time": "2020-01-24T14:09:18.953622Z"
    }
   },
   "outputs": [],
   "source": [
    "pi = pi.rename(columns={' ORGANIZATION_CITY':'city'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:19.805744Z",
     "start_time": "2020-01-24T14:09:19.634521Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_name_location_city = inventors.merge(pi, on=['name_first','name_last','name_middle','state','city'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many matches did we get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:20.358641Z",
     "start_time": "2020-01-24T14:09:20.351231Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_name_location_city['inventor_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:21.053118Z",
     "start_time": "2020-01-24T14:09:20.885688Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_phonetic_name_location_city = inventors.merge(pi, on=['phonetic_first','phonetic_last','state','city'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:09:21.677570Z",
     "start_time": "2020-01-24T14:09:21.660224Z"
    }
   },
   "outputs": [],
   "source": [
    "merge_phonetic_name_location_city['inventor_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">**Checkpoint 3: Deterministic matching of organization names**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try doing different types of merges using organization names, blocking on different variables and seeing the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T14:07:30.224447Z",
     "start_time": "2020-01-24T14:07:30.215459Z"
    }
   },
   "outputs": [],
   "source": [
    "# your code here...\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: Regular Expressions - regex**\n",
    "\n",
    "When defining a regular expression search pattern, it is a good idea to start out by writing down, explicitly, in plain English, what you are trying to search for and exactly how you identify when you've found a match.\n",
    "For example, if we look at an author field formatted as \"<last_name> , <first_name> <middle_name>\", in plain English, this is how I would explain where to find the last name: \"starting from the beginning of the line, take all the characters until you see a comma.\"\n",
    "\n",
    "We can build a regular expression that captures this idea from the following components:\n",
    "- ^ Matches beginning of the line\n",
    "- . Matches any character\n",
    "- .+ A modifier that means \"match one or more of the preceding expression\"\n",
    "\n",
    "In a regular expression, there are special reserved characters and character classes like those in the list above. Anything that is not a special character or class is just looked for explicitly (for example, a comma is not a special character in regular expressions, so if it is in a regular expression pattern, the regular expression processor will just be looking for a comma in the string, at that point in the pattern).\n",
    "\n",
    "Note: if you want to actually look for one of these reserved characters, it must be escaped, so that, for example, the expression looks for a literal period, rather than the special regular expression meaning of a period. To escape a reserved character in a regular expression, precede it with a back slash ( \".\" ).\n",
    "This results in the regular expression: ^.+,\n",
    "\n",
    "We start at the beginning of the line ( \"^\" ), matching any characters ( \".+\" ) until we come to the literal character of a comma ( \",\" ).\n",
    "\n",
    "In python, to use a regular expression like this to search for matches in a given string, we use the built-in \"re\" package ( https://docs.python.org/2/library/re.html ), specifically the \"re.search()\" method. To use \"re.search()\", pass it first the regular expression you want to use to search, enclosed in quotation marks, and then the string you want to search within. \n",
    "\n",
    "#### REGEX CHEATSHEET\n",
    "\n",
    "\n",
    "    - abc...     Letters\n",
    "    - 123...     Digits\n",
    "    - \\d         Any Digit\n",
    "    - \\D         Any non-Digit Character\n",
    "    - .          Any Character\n",
    "    - \\.         Period\n",
    "    - [a,b,c]    Only a, b or c\n",
    "    - [^a,b,c]   Not a,b, or c\n",
    "    - [a-z]      Characters a to z\n",
    "    - [0-9]      Numbers 0 to 9\n",
    "    - \\w any     Alphanumeric chracter\n",
    "    - \\W         any non-Alphanumeric character\n",
    "    - {m}        m Repetitions\n",
    "    - {m,n}      m to n repetitions\n",
    "    - *          Zero or more repetitions\n",
    "    - +          One or more repetitions\n",
    "    - ?          Optional Character\n",
    "    - \\s         any Whitespace\n",
    "    - \\S         any non-Whitespace character\n",
    "    - ^...$      Starts & Ends\n",
    "    - (...)      Capture Group\n",
    "    - (a(bc))    Capture sub-Group\n",
    "    - (.*)       Capture All\n",
    "    - (abc|def)  Capture abc or def\n",
    "     \n",
    "#### EXAMPLES\n",
    "    - (\\d\\d|\\D) will match 22X, 23G, 56H, etc...\n",
    "    - \\w will match any characters between 0-9 or a-z\n",
    "    - \\w{1-3} will match any alphanumeric character of a length of 1 to 3. \n",
    "    - (spell|spells) will match spell or spells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Further Readings\n",
    "\n",
    "\n",
    "### Record Linkage\n",
    "Winkler, William E. 2009. “Record Linkage.” In Handbook of Statistics 29a, Sample Surveys: Design, Methods and Applications, edited by D. Pfeffermann and C.\n",
    "R. Rao, 351–80. Elsevier.\n",
    "\n",
    "Lane, Julia, Ian Foster, Rayid Ghani, Ron S. Jarmin, Frauke Kreuter (editors), Big Data and Social Science: A Practical Guide to Methods and Tools, Chapman and Hall/CRC Press, 2016. \n",
    "https://coleridge-initiative.github.io/big-data-and-social-science/chap-link.html\n",
    "\n",
    "### Parsing\n",
    "\n",
    "* Python online documentation: https://docs.python.org/2/library/string.html#deprecated-string-functions\n",
    "* Python 2.7 Tutorial (Splitting and Joining Strings): http://www.pitt.edu/~naraehan/python2/split_join.html\n",
    "\n",
    "### Regular Expression\n",
    "\n",
    "* Python documentation: https://docs.python.org/2/library/re.html#regular-expression-syntax\n",
    "* Online regular expression tester (good for learning): http://regex101.com/\n",
    "\n",
    "### Record Linkage Python package\n",
    "* `recordlinkage` Python package: https://recordlinkage.readthedocs.io/en/latest/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
