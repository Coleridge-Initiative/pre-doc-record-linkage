{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Coleridge Initiative Logo](images/CI_horizontal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <span style=\"font-size: 1.5em;\">\n",
    "        <a href='https://www.coleridgeinitiative.org'>Website</a>\n",
    "    </span>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contributors: Ghani, Rayid, Frauke Kreuter, Julia Lane, Brian Kim, Adrianne Bradford, Alex Engler, Nicolas Guetta Jeanrenaud, Graham Henke, Daniela Hochfellner, Clayton Hunter, Avishek Kumar, Jonathan Morgan, Ekaterina Levitskaya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Python-Setup\" data-toc-modified-id=\"Python-Setup-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Python Setup</a></span></li><li><span><a href=\"#Data-Import\" data-toc-modified-id=\"Data-Import-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Import</a></span></li><li><span><a href=\"#Record-Linkage\" data-toc-modified-id=\"Record-Linkage-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Record Linkage</a></span><ul class=\"toc-item\"><li><span><a href=\"#Indexing\" data-toc-modified-id=\"Indexing-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Indexing</a></span></li></ul></li><li><span><a href=\"#Record-Comparison\" data-toc-modified-id=\"Record-Comparison-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Record Comparison</a></span><ul class=\"toc-item\"><li><span><a href=\"#Classification\" data-toc-modified-id=\"Classification-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Classification</a></span></li></ul></li><li><span><a href=\"#References-and-Further-Readings\" data-toc-modified-id=\"References-and-Further-Readings-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>References and Further Readings</a></span><ul class=\"toc-item\"><li><span><a href=\"#Record-Linkage\" data-toc-modified-id=\"Record-Linkage-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Record Linkage</a></span></li><li><span><a href=\"#Record-Linkage-Python-package\" data-toc-modified-id=\"Record-Linkage-Python-package-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Record Linkage Python package</a></span></li><li><span><a href=\"#String-Comparators\" data-toc-modified-id=\"String-Comparators-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>String Comparators</a></span></li><li><span><a href=\"#Fellegi-Sunter-Record-Linkage\" data-toc-modified-id=\"Fellegi-Sunter-Record-Linkage-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Fellegi-Sunter Record Linkage</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T23:57:01.563980Z",
     "start_time": "2020-01-24T23:57:01.554186Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data import and manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# record linkage and preprocessing\n",
    "import recordlinkage as rl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read-in previously cleaned datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T23:57:29.305063Z",
     "start_time": "2020-01-24T23:57:28.922229Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read-in files with cleaned inventors (PatentsView) and principal investigators (FedRePORTER) names\n",
    "inventors = pd.read_csv('../Data/inventors_cleaned.csv')\n",
    "pi = pd.read_csv('../Data/pi_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T23:57:29.543162Z",
     "start_time": "2020-01-24T23:57:29.510059Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View first rows of the table\n",
    "inventors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T23:57:30.018666Z",
     "start_time": "2020-01-24T23:57:29.992371Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View first rows of the table\n",
    "pi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T23:57:13.475095Z",
     "start_time": "2020-01-24T23:57:13.290417Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read-in files with cleaned organization names in PatentsView (assignees) and FedRePORTER (organizations)\n",
    "assignees = pd.read_csv('../Data/assignees_cleaned.csv')\n",
    "organizations = pd.read_csv('../Data/organizations_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:06:36.257569Z",
     "start_time": "2020-01-24T21:06:36.235856Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View first rows of the table\n",
    "assignees.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T21:06:46.903484Z",
     "start_time": "2020-01-24T21:06:46.886773Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# View first rows of the table\n",
    "organizations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T14:52:49.770491Z",
     "start_time": "2020-01-21T14:52:49.757602Z"
    }
   },
   "source": [
    "## Record Linkage\n",
    "\n",
    "The `recordlinkage` package is a quite powerful tool for you to use when you want to link records within a dataset or across multiple datasets. We've already done some pre-processing and then tried deterministic matching.\n",
    "\n",
    "However, as we have seen in the previous notebook, we might want to consider how strict we want our matching to be. For example, we want to make sure that we catch any typos or common misspellings, but we want to avoid relaxing the matching condition to the point that anything will match anything. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Indexing allows us to create candidate links, which basically means identifying pairs of data rows which might refer to the same real world entity. This is also called the comparison space (matrix). There are different ways to index data. The easiest is to create a full index and consider every pair a match. This is also the least efficient method, because we will be comparing every row of one dataset with every row of the other dataset.\n",
    "\n",
    "If we had 10,000 records in data frame A and 100,000 records in data frame B, we would have 1,000,000,000 candidate links. You can see that comparing over a full index is getting inefficient when working with big data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do better if we actually include our knowledge about the data to eliminate bad link from the start. This can be done through blocking. The `recordlinkage` package gives you multiple options for this. For example, you can block by using variables, which means only links exactly equal on specified values will be kept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will start by blocking on `city` and `state`, to narrow down the number of candidate links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try and see how the number of candidate links change when blocking on more or less variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T23:59:58.508988Z",
     "start_time": "2020-01-24T23:59:58.285681Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexerBL = rl.BlockIndex(on=['city', 'state'])\n",
    "candidate_links = indexerBL.index(inventors, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T23:59:59.123991Z",
     "start_time": "2020-01-24T23:59:59.112754Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(candidate_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:00:01.693948Z",
     "start_time": "2020-01-25T00:00:01.682850Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candidate_links[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the first pair of candidate links blocked on city and state: (0, 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:00:12.062388Z",
     "start_time": "2020-01-25T00:00:12.047911Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inventors.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:00:14.540037Z",
     "start_time": "2020-01-25T00:00:14.529354Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi.iloc[85]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:01:20.037083Z",
     "start_time": "2020-01-25T00:01:19.922687Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, in addition to blocking on city and state, we can also try blocking on first name\n",
    "indexerBL = rl.BlockIndex(on=['name_first','city', 'state'])\n",
    "candidate_links = indexerBL.index(inventors, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:01:20.430544Z",
     "start_time": "2020-01-25T00:01:20.422614Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(candidate_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Comparison\n",
    "\n",
    "After you have created a set of candidate links, you’re ready to begin comparing the records associated with each candidate link. In `recordlinkage` package you must initiate a Compare object prior to performing any comparison functionality between records. This object stores both dataframes, the candidate links, and a vector containing comparison results. Further, the Compare object contains the methods for performing comparisons. The code block below initializes the comparison object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:08:27.443502Z",
     "start_time": "2020-01-25T00:08:27.436868Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate compare object \n",
    "compare_cl = rl.Compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently there are five specific comparison methods within recordlinkage: `Compare.exact()`, `Compare.string()`, `Compare.numeric()`, `Compare.geo()`, and `Compare.date()`. \n",
    "\n",
    "The `Compare.exact()` method is simple: if two values are an exact match a comparison score of 1 is returned, otherwise 0 is retured. \n",
    "\n",
    "The `Compare.string()` method is a bit more complicated and generates a score based on well-known string-comparison algorithms (for this example, Levenshtein or Jaro Winkler)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python `recordlinkage` toolkit uses the `jellyfish` package for the Jaro, Jaro-Winkler, Levenshtein and Damerau-Levenshtein algorithms: https://jellyfish.readthedocs.io/en/latest/comparison.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be a large difference in the performance of different string comparison algorithms. The Jaro and Jaro-Winkler methods are faster than the Levenshtein distance and much faster than the Damerau-Levenshtein distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "String similarity measures and phonetic encodings are computationally expensive. After phonetic encoding of the string variables, exact comparing can be used instead of computing the string similarity of all record pairs. If the number of candidate pairs is much larger than the number of records in both datasets together, then consider using phonetic encoding of string variables instead of string comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Choose and compare only informative variables: not all variables may be worth comparing in a record linkage. Some variables do not discriminate the links of the non-links or do have only minor effects. These variables can be excluded. Only informative variables should be included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example, Jaro-Winkler distance is used (specifically developed with record linkage applications in mind, faster to compute) - words with more characters in common have a higher Jaro-Winkler value than those with fewer characters in common. The Jaro–Winkler distance gives more favorable ratings to strings that match from the beginning. The output value is normalized to fall between 0 (complete dissimilar strirngs) and 1 (exact match on strings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you remember, we already did an exact matching on `city` and `state`, when we did the blocking above and created the candidate links.\n",
    "\n",
    "We will use the string method to compare the organization names and their phonetic transcriptions.\n",
    "\n",
    "We need to specify the respective columns with organization names in both datasets, the method, and the threshold. In this case, for all strings that have more than 85% in similarity, according to the Jaro-Winkler distance, a 1 will be returned, and otherwise 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:58:03.735472Z",
     "start_time": "2020-01-25T00:58:03.727347Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initiate compare object \n",
    "compare_cl = rl.Compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:58:11.782298Z",
     "start_time": "2020-01-25T00:58:11.775992Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "compare_cl.string('name_first', 'name_first', method='jarowinkler', threshold=0.85, label='name_first')\n",
    "compare_cl.string('name_last', 'name_last', method='jarowinkler', threshold=0.85, label='name_last')\n",
    "\n",
    "#compare_cl.exact('state', 'state', label='state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparing of record pairs starts when the `compute` method is called."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:58:19.662962Z",
     "start_time": "2020-01-25T00:58:19.459070Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indexerBL = rl.BlockIndex(on=['city', 'state'])\n",
    "candidate_links = indexerBL.index(inventors, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:58:27.241285Z",
     "start_time": "2020-01-25T00:58:27.236823Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(candidate_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:58:39.959378Z",
     "start_time": "2020-01-25T00:58:35.241321Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## All attribute comparisons are stored in a DataFrame with horizontally the features and vertically the record pairs.\n",
    "features = compare_cl.compute(candidate_links, inventors, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:58:48.506100Z",
     "start_time": "2020-01-25T00:58:48.495669Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:58:57.579012Z",
     "start_time": "2020-01-25T00:58:57.569418Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Let's check how many records we get where one or more comparison attributes match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:59:06.405426Z",
     "start_time": "2020-01-25T00:59:06.279609Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Simple Classification: Check for how many attributes records are identical by summing the comparison results.\n",
    "features.sum(axis=1).value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a decision now, and consider matches all those records which matched on all attributes in our case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:59:15.322754Z",
     "start_time": "2020-01-25T00:59:15.227346Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches = features[features.sum(axis=1) == 2]\n",
    "print(len(matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that for these matches we had an exact match on `city` and `state`, and more than 80% in similarity based on organization `first name` and `last name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:59:24.818053Z",
     "start_time": "2020-01-25T00:59:24.808432Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's merge these matches back to original dataframes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `matches` dataframe has MultiIndex - two indices to the left which correspond to the `inventor` table and `pi` table respectively.\n",
    "\n",
    "We can access each matching pair individually, for example, the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:59:35.695051Z",
     "start_time": "2020-01-25T00:59:35.684718Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do the following: first, put all the indices for the `inventors` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:59:46.214270Z",
     "start_time": "2020-01-25T00:59:46.207632Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matches.index[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will pull all corresponding rows from the `inventors` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T00:59:55.834746Z",
     "start_time": "2020-01-25T00:59:55.563608Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inventors_results = []  # Create an empty list\n",
    "\n",
    "for match in matches.index:  # For every pair in matches (index)\n",
    "    df = pd.DataFrame(inventors.loc[[match[0]]])  # Get the location in the original table, convert to dataframe\n",
    "    inventors_results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:00:05.570090Z",
     "start_time": "2020-01-25T01:00:05.543440Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inventors_results[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we concatenate the list of dataframes into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:00:15.274102Z",
     "start_time": "2020-01-25T01:00:14.975412Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inventors_concat = pd.concat(inventors_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:00:23.851539Z",
     "start_time": "2020-01-25T01:00:23.837127Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inventors_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same for the `pi` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:00:32.672249Z",
     "start_time": "2020-01-25T01:00:32.380570Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi_results = []  # Create an empty list\n",
    "\n",
    "for match in matches.index:  # For every pair in matches (index)\n",
    "    df = pd.DataFrame(pi.loc[[match[1]]])  # Get the location in the original table, convert to dataframe\n",
    "    pi_results.append(df)\n",
    "    \n",
    "pi_concat = pd.concat(pi_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:00:40.565857Z",
     "start_time": "2020-01-25T01:00:40.550235Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to combine two tables on the index - notice that our tables right now have indices from the original tables. We can reset the index using `.reset_index()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:00:48.748549Z",
     "start_time": "2020-01-25T01:00:48.740396Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inventors_concat = inventors_concat.reset_index()\n",
    "pi_concat = pi_concat.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our tables have the same index on which we can combine two tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:00:56.818210Z",
     "start_time": "2020-01-25T01:00:56.801690Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inventors_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:01:05.674458Z",
     "start_time": "2020-01-25T01:01:05.658654Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pi_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:01:14.254964Z",
     "start_time": "2020-01-25T01:01:14.247450Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop the old index column\n",
    "inventors_concat = inventors_concat.drop(columns=['index'])\n",
    "pi_concat = pi_concat.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:01:22.447320Z",
     "start_time": "2020-01-25T01:01:22.441237Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop other not relevant columns\n",
    "inventors_concat = inventors_concat.drop(columns=['inventor_country'])\n",
    "pi_concat = pi_concat.drop(columns=[' ORGANIZATION_COUNTRY'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we concatenate these two tables using `.concat()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:01:30.508213Z",
     "start_time": "2020-01-25T01:01:30.502697Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matched = pd.concat([inventors_concat, pi_concat], axis=1)  # Specify axis=1 to concatenate horizontally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-25T01:03:18.489497Z",
     "start_time": "2020-01-25T01:03:18.453370Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matched[14:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have merged our matches together, examine them. Remember that we matched our strings on 85% similarity, according to the Jaro-Winkler distance,  and we blocked on city and state. Try using a different threshold. You can also use a different string-matching algorithm (please see below in References)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-22T13:27:51.524520Z",
     "start_time": "2020-01-22T13:27:51.516843Z"
    }
   },
   "source": [
    "<span style=\"color:red\">**Checkpoint: Record Linkage Decisions**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are some decisinos we had to make as we went through the record linkage process above? What if we had made different choices instead?\n",
    "\n",
    "Try doing the record linkage with a few different options and see how many matches you get as you vary the approach. For example, try different string-matching algorithms or thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-24T20:19:38.619193Z",
     "start_time": "2020-01-24T20:19:36.425Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# your code here...\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References and Further Readings\n",
    "\n",
    "### Record Linkage\n",
    "\n",
    "Lane, Julia, Ian Foster, Rayid Ghani, Ron S. Jarmin, Frauke Kreuter (editors), Big Data and Social Science: A Practical Guide to Methods and Tools, Chapman and Hall/CRC Press, 2016. https://coleridge-initiative.github.io/big-data-and-social-science/chap-link.html\n",
    "\n",
    "### Record Linkage Python package\n",
    "* `recordlinkage` Python package: https://recordlinkage.readthedocs.io/en/latest/index.html\n",
    "    - Comparing records: https://recordlinkage.readthedocs.io/en/latest/ref-compare.html\n",
    "    - Classification:\n",
    "        - https://recordlinkage.readthedocs.io/en/latest/ref-classifiers.html,\n",
    "        - https://recordlinkage.readthedocs.io/en/latest/notebooks/classifiers.html\n",
    "\n",
    "### String Comparators\n",
    "\n",
    "* GitHub page of `jellyfish`: https://github.com/jamesturk/jellyfish\n",
    "* Descriptions of distances in `jellyfish`: https://jellyfish.readthedocs.io/en/latest/comparison.html\n",
    "* Different distances that measure the differences between strings:\n",
    "    - Levenshtein distance: https://en.wikipedia.org/wiki/Levenshtein_distance\n",
    "    - Damerau–Levenshtein distance: https://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance\n",
    "    - Jaro–Winkler distance: https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance\n",
    "    - Hamming distance: https://en.wikipedia.org/wiki/Hamming_distance\n",
    "    - Match rating approach: https://en.wikipedia.org/wiki/Match_rating_approach\n",
    "\n",
    "### Fellegi-Sunter Record Linkage \n",
    "\n",
    "* Introduction to Probabilistic Record Linkage: http://www.bristol.ac.uk/media-library/sites/cmm/migrated/documents/problinkage.pdf\n",
    "* Paper Review: https://www.cs.umd.edu/class/spring2012/cmsc828L/Papers/HerzogEtWires10.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3-RecLink",
   "language": "python",
   "name": "py3-rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
